{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date accessed: 2024-10-21 23:52:03\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# print date as date accessed\n",
    "date_accessed = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(f\"Date accessed: {date_accessed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import dask\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import os, sys, glob, re, time, math, calendar, ast\n",
    "import yaml\n",
    "\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "import pickle\n",
    "from pickle import dump, load\n",
    "import joblib\n",
    "\n",
    "import torch\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# import custom functions\n",
    "sys.path.append('/')\n",
    "from libraries import *\n",
    "from plotters import *\n",
    "\n",
    "#For reproducibility of the results, the following seeds should be selected \n",
    "from numpy.random import seed\n",
    "randSeed = np.random.randint(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.argv = ['','PROF_OWEG', 0]\n",
    "# === Input parameters ===\n",
    "input_file = 'data/ERA5.nc'\n",
    "input_variables = [\n",
    "    \"10ws\", \"100ws\", \"100alpha\", \"975ws\", \"950ws\", \"975wsgrad\", \"950wsgrad\",\n",
    "    \"zust\", \"i10fg\", \"t2m\", \"skt\", \"stl1\", \"d2m\", \"msl\", \"blh\", \"cbh\", \"ishf\", \n",
    "    \"ie\", \"tcc\", \"lcc\", \"cape\", \"cin\", \"bld\", \"t_975\", \"t_950\", \"2mtempgrad\", \n",
    "    \"sktempgrad\", \"dewtempsprd\", \"975tempgrad\", \"950tempgrad\", \"sinHR\", \n",
    "    \"cosHR\", \"sinJDAY\", \"cosJDAY\"\n",
    "]\n",
    "input_times_freq = 1 #ratio between the target times and input times\n",
    "\n",
    "station_id = sys.argv[1]\n",
    "Coeff_file = f'data/Profiler_Chebyshev_Coefficients/{station_id}.nc'\n",
    "target_variables = [0,1,2,3,4]\n",
    "\n",
    "train_dates_range = ('2018-01-01T00:00:00', '2019-12-31T23:00:00')\n",
    "test_dates_range = ('2020-01-01T00:00:00', '2020-12-31T23:00:00')\n",
    "\n",
    "experiment = f'ERA5_to_profilers'\n",
    "\n",
    "tabnet_param_file = 'tabnet_params_8th_set.csv'\n",
    "Ens = int(sys.argv[2])\n",
    "\n",
    "model_output_dir = f'trained_models/{experiment}/{station_id}/Ens{Ens}'\n",
    "os.system(f'mkdir -p {model_output_dir}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8585, 34) (8585, 5) (2132, 34) (2132, 5)\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_valid, Y_valid = data_processing(input_file,Coeff_file,\n",
    "                                                    input_times_freq,input_variables,target_variables,train_dates_range,station_id,val_arg=True)\n",
    "print(X_train.shape, Y_train.shape, X_valid.shape, Y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5721, 34) (5721, 5)\n"
     ]
    }
   ],
   "source": [
    "X_test, Y_test = data_processing(input_file,Coeff_file,\n",
    "                                input_times_freq,input_variables,target_variables,test_dates_range,station_id)\n",
    "print(X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === load tabnet parameters ===\n",
    "tabnet_params = pd.read_csv(tabnet_param_file)\n",
    "n_d = int(tabnet_params['n_d'][Ens])\n",
    "n_a = int(tabnet_params['n_a'][Ens])\n",
    "n_steps = int(tabnet_params['n_steps'][Ens])\n",
    "n_independent = int(tabnet_params['n_independent'][Ens])\n",
    "n_shared = int(tabnet_params['n_shared'][Ens])\n",
    "gamma = float(tabnet_params['gamma'][Ens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harish/miniconda3/envs/TabNet_env/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    }
   ],
   "source": [
    "# === training the tabnet model ===#\n",
    "tabReg   = TabNetRegressor(n_d = n_d, \n",
    "                                n_a = n_a, \n",
    "                                n_steps = n_steps,\n",
    "                                n_independent = n_independent,\n",
    "                                n_shared = n_shared,\n",
    "                                gamma = gamma,\n",
    "                                verbose=1,seed=randSeed, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 12.02537| train_rmse: 46.36077| valid_rmse: 46.6163 |  0:00:00s\n",
      "epoch 1  | loss: 4.12898 | train_rmse: 10.22573| valid_rmse: 10.03505|  0:00:01s\n",
      "epoch 2  | loss: 2.80396 | train_rmse: 8.40599 | valid_rmse: 8.41363 |  0:00:01s\n",
      "epoch 3  | loss: 2.49775 | train_rmse: 5.73398 | valid_rmse: 5.6133  |  0:00:02s\n",
      "epoch 4  | loss: 2.31139 | train_rmse: 2.85369 | valid_rmse: 2.60569 |  0:00:02s\n",
      "epoch 5  | loss: 2.24319 | train_rmse: 3.11946 | valid_rmse: 2.78282 |  0:00:02s\n",
      "epoch 6  | loss: 2.14413 | train_rmse: 2.27251 | valid_rmse: 2.03262 |  0:00:03s\n",
      "epoch 7  | loss: 2.11175 | train_rmse: 2.28069 | valid_rmse: 2.18468 |  0:00:03s\n",
      "epoch 8  | loss: 2.07804 | train_rmse: 1.95264 | valid_rmse: 1.77737 |  0:00:04s\n",
      "epoch 9  | loss: 2.06578 | train_rmse: 1.92366 | valid_rmse: 1.77328 |  0:00:04s\n",
      "epoch 10 | loss: 1.98482 | train_rmse: 1.75745 | valid_rmse: 1.63531 |  0:00:05s\n",
      "epoch 11 | loss: 2.06887 | train_rmse: 1.74855 | valid_rmse: 1.64649 |  0:00:05s\n",
      "epoch 12 | loss: 2.00311 | train_rmse: 1.63153 | valid_rmse: 1.47057 |  0:00:05s\n",
      "epoch 13 | loss: 1.99516 | train_rmse: 1.64352 | valid_rmse: 1.47857 |  0:00:06s\n",
      "epoch 14 | loss: 1.95605 | train_rmse: 1.58861 | valid_rmse: 1.38561 |  0:00:06s\n",
      "epoch 15 | loss: 1.96761 | train_rmse: 1.5646  | valid_rmse: 1.40074 |  0:00:07s\n",
      "epoch 16 | loss: 1.93078 | train_rmse: 1.5824  | valid_rmse: 1.41482 |  0:00:07s\n",
      "epoch 17 | loss: 1.94602 | train_rmse: 1.53083 | valid_rmse: 1.37282 |  0:00:08s\n",
      "epoch 18 | loss: 1.87429 | train_rmse: 1.5398  | valid_rmse: 1.39501 |  0:00:08s\n",
      "epoch 19 | loss: 1.91171 | train_rmse: 1.48939 | valid_rmse: 1.35159 |  0:00:09s\n",
      "epoch 20 | loss: 1.90363 | train_rmse: 1.47708 | valid_rmse: 1.36612 |  0:00:09s\n",
      "epoch 21 | loss: 1.84929 | train_rmse: 1.42327 | valid_rmse: 1.33135 |  0:00:09s\n",
      "epoch 22 | loss: 1.86742 | train_rmse: 1.4112  | valid_rmse: 1.3016  |  0:00:10s\n",
      "epoch 23 | loss: 1.83689 | train_rmse: 1.40434 | valid_rmse: 1.29164 |  0:00:10s\n",
      "epoch 24 | loss: 1.83077 | train_rmse: 1.33776 | valid_rmse: 1.29356 |  0:00:11s\n",
      "epoch 25 | loss: 1.81833 | train_rmse: 1.34555 | valid_rmse: 1.24181 |  0:00:11s\n",
      "epoch 26 | loss: 1.85046 | train_rmse: 1.36762 | valid_rmse: 1.28458 |  0:00:12s\n",
      "epoch 27 | loss: 1.82561 | train_rmse: 1.31161 | valid_rmse: 1.26947 |  0:00:12s\n",
      "epoch 28 | loss: 1.78656 | train_rmse: 1.3074  | valid_rmse: 1.25832 |  0:00:12s\n",
      "epoch 29 | loss: 1.78216 | train_rmse: 1.29483 | valid_rmse: 1.23915 |  0:00:13s\n",
      "epoch 30 | loss: 1.81239 | train_rmse: 1.29286 | valid_rmse: 1.34387 |  0:00:13s\n",
      "epoch 31 | loss: 1.82999 | train_rmse: 1.30364 | valid_rmse: 1.21853 |  0:00:14s\n",
      "epoch 32 | loss: 1.73982 | train_rmse: 1.29838 | valid_rmse: 1.25192 |  0:00:14s\n",
      "epoch 33 | loss: 1.69116 | train_rmse: 1.29897 | valid_rmse: 1.2666  |  0:00:15s\n",
      "epoch 34 | loss: 1.75132 | train_rmse: 1.27729 | valid_rmse: 1.32541 |  0:00:15s\n",
      "epoch 35 | loss: 1.71926 | train_rmse: 1.25726 | valid_rmse: 1.32034 |  0:00:15s\n",
      "epoch 36 | loss: 1.67617 | train_rmse: 1.25079 | valid_rmse: 1.38087 |  0:00:16s\n",
      "epoch 37 | loss: 1.69319 | train_rmse: 1.26105 | valid_rmse: 1.45567 |  0:00:16s\n",
      "epoch 38 | loss: 1.65714 | train_rmse: 1.25694 | valid_rmse: 1.37913 |  0:00:17s\n",
      "epoch 39 | loss: 1.7298  | train_rmse: 1.25541 | valid_rmse: 1.29105 |  0:00:17s\n",
      "epoch 40 | loss: 1.6601  | train_rmse: 1.23612 | valid_rmse: 1.24378 |  0:00:18s\n",
      "epoch 41 | loss: 1.63035 | train_rmse: 1.24514 | valid_rmse: 1.43535 |  0:00:18s\n",
      "\n",
      "Early stopping occurred at epoch 41 with best_epoch = 31 and best_valid_rmse = 1.21853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harish/miniconda3/envs/TabNet_env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    }
   ],
   "source": [
    "tabReg.fit(X_train=X_train, y_train=Y_train,\n",
    "                    eval_set=[(X_train, Y_train), (X_valid, Y_valid)],\n",
    "                    eval_name=['train', 'valid'],\n",
    "                    max_epochs=250, batch_size=512,    #bSize_opt.item(), \n",
    "                    eval_metric=['rmse'], patience=10,  #mae, rmse\n",
    "                    loss_fn = torch.nn.MSELoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dumped\n"
     ]
    }
   ],
   "source": [
    "fSTR = f'{model_output_dir}/TabNet_HOLDOUT.pkl'\n",
    "with open(fSTR, \"wb\") as f:\n",
    "    dump(tabReg, f, pickle.HIGHEST_PROTOCOL)\n",
    "print('dumped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plot loss curve and hexbin ---\n",
    "fig = plt.figure(figsize=(18, 3), constrained_layout=True)\n",
    "gs = fig.add_gridspec(1,6)\n",
    "\n",
    "# Line plot for train and validation RMSE\n",
    "ax = fig.add_subplot(gs[0])\n",
    "ax.plot(tabReg.history['train_rmse'],'--', label='train')\n",
    "ax.plot(tabReg.history['valid_rmse'],':', label='validation')\n",
    "ax.set_title('Training and Validation RMSE')\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('RMSE')\n",
    "ax.legend()\n",
    "\n",
    "Y_pred = tabReg.predict(X_valid)\n",
    "#Y_pred = min_max_scaler.inverse_transform(Y_pred)\n",
    "\n",
    "for j,target_variable in enumerate(target_variables):\n",
    "    hexbin_plotter(fig,gs[j+1],Y_valid[:,target_variable],Y_pred[:,target_variable],f'Coefficient {target_variable}',text_arg=True, xlabel='True', ylabel='Predicted')\n",
    "fig.suptitle(f\"n_d:{n_d}, n_a:{n_a}, n_steps:{n_steps}, n_independent:{n_independent}, n_shared:{n_shared}, gamma:{gamma}\")\n",
    "\n",
    "plt.savefig(f'{model_output_dir}/TabNet_HOLDOUT.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TabNet_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
