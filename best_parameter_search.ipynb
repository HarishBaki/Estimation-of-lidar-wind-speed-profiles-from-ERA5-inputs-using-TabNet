{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date accessed: 2024-10-22 22:58:08\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# print date as date accessed\n",
    "date_accessed = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(f\"Date accessed: {date_accessed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import dask\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import os, sys, glob, re, time, math, calendar, ast\n",
    "import yaml\n",
    "\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "import pickle\n",
    "from pickle import dump, load\n",
    "import joblib\n",
    "\n",
    "import torch\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# import custom functions\n",
    "sys.path.append('/')\n",
    "from libraries import *\n",
    "from plotters import *\n",
    "\n",
    "#For reproducibility of the results, the following seeds should be selected \n",
    "randSeed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = ['', 'PROF_QUEE','Averaged_over_55th_to_5th_min', 'segregated', 'not_transformed','Kho_loss_on_profile',0,  42, 0, 80, \"1\"]    # for debugging\n",
    "station_id = sys.argv[1]\n",
    "hourly_data_method = sys.argv[2]\n",
    "train_dates_range = ('2021-01-01T00:00:00', '2023-12-31T23:00:00')\n",
    "\n",
    "# Extract years from the date range\n",
    "start_date = datetime.fromisoformat(train_dates_range[0])\n",
    "end_date = datetime.fromisoformat(train_dates_range[1])\n",
    "# Get the years\n",
    "start_year = start_date.year\n",
    "end_year = end_date.year\n",
    "# Format the folder name\n",
    "if start_year == end_year:\n",
    "    years_experiment = f\"{start_year}\"\n",
    "else:\n",
    "    years_experiment = f\"{start_year}_to_{end_year}\"\n",
    "\n",
    "experiment = f'ERA5_to_profilers'\n",
    "\n",
    "segregated = sys.argv[3]\n",
    "transformed = sys.argv[4]\n",
    "loss_function = sys.argv[5]\n",
    "\n",
    "# Initialize an empty list to store the model parameters for each Ens\n",
    "model_data = []\n",
    "\n",
    "for Ens in range(0,10):\n",
    "    model_output_dir = f'trained_models/{experiment}/{station_id}/{hourly_data_method}/{years_experiment}/{segregated}/{transformed}/{loss_function}/Ens{Ens}'\n",
    "    valMin = 1e8\n",
    "    best_model_params = {}\n",
    "    for trial in range(0,100):\n",
    "        fSTR = f'{model_output_dir}/trial{trial}/TabNet_HOLDOUT.pkl'\n",
    "        with open(fSTR, \"rb\") as f:\n",
    "            tabReg = pickle.load(f)\n",
    "        rmseVal = tabReg.history['valid_rmse'][tabReg.best_epoch]\n",
    "        if rmseVal < valMin: \n",
    "            valMin = rmseVal\n",
    "\n",
    "            # Save the best model's parameters\n",
    "            best_model_params = {\n",
    "                'n_d': tabReg.n_d,\n",
    "                'n_a': tabReg.n_a,\n",
    "                'n_steps': tabReg.n_steps,\n",
    "                'n_independent': tabReg.n_independent,\n",
    "                'n_shared': tabReg.n_shared,\n",
    "                'gamma': tabReg.gamma,\n",
    "            }\n",
    "            \n",
    "            fSTR = f'{model_output_dir}/TabNet_HOLDOUT.pkl'\n",
    "            with open(fSTR, \"wb\") as f:\n",
    "                dump(tabReg, f, pickle.HIGHEST_PROTOCOL)\n",
    "            print('dumped')\n",
    "            print(Ens, trial, valMin)\n",
    "    \n",
    "    # Append the best model's parameters for this Ens to the list\n",
    "    model_data.append([Ens, best_model_params['n_d'], best_model_params['n_a'], \n",
    "                       best_model_params['n_steps'], best_model_params['n_independent'], \n",
    "                       best_model_params['n_shared'], best_model_params['gamma']])\n",
    "\n",
    "# Create a DataFrame from the collected model data\n",
    "df = pd.DataFrame(model_data, columns=['Ens', 'n_d', 'n_a', 'n_steps', 'n_independent', 'n_shared', 'gamma'])\n",
    "\n",
    "# Set Ens as the index\n",
    "df.set_index('Ens', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('best_model_params.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TabNet_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
