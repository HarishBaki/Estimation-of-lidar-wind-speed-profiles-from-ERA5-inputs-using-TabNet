{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date accessed: 2025-03-11 16:30:20\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# print date as date accessed\n",
    "date_accessed = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(f\"Date accessed: {date_accessed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prior to this script, the ERA5 input variables at location specifics are extracted using the following script\n",
    "    -   Extrating_ERA5_variables.py\n",
    "    -   combining_yearly_ERA5.py, and  \n",
    "    -   run_all_ERA5_extraction.sh "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import dask\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import os, sys, glob, re, time, math, calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Checking the 2018 Oct data. Turns out, u100 and v100 are nans during this month. \\nyear = 2018\\nmonth = 10\\nfile = glob.glob(f'/data/harish/Estimation-of-lidar-wind-speed-profiles-from-ERA5-inputs-using-TabNet/data/{year}/SFC_{year}_{month:02d}*')[0]\\nhr_data = xr.open_dataset(file, engine='netcdf4')\\nhr_data\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Checking the 2018 Oct data. Turns out, u100 and v100 are nans during this month. \n",
    "year = 2018\n",
    "month = 10\n",
    "file = glob.glob(f'/data/harish/Estimation-of-lidar-wind-speed-profiles-from-ERA5-inputs-using-TabNet/data/{year}/SFC_{year}_{month:02d}*')[0]\n",
    "hr_data = xr.open_dataset(file, engine='netcdf4')\n",
    "hr_data\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Execute the following scripts only if you intend to begin from scratch. \n",
    "- If you intend to add/compute new features, start from [add new features](#adding-new-features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute ML inputs derived from ERA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_wind_speed(par_name1,par_name2, par_name):\n",
    "    ds1 = xr.open_dataset(f'data/ERA5_variables/{par_name1}.nc',chunks={'lat': -1, 'lon': -1, 'time': -1}).compute()\n",
    "    print(ds1)\n",
    "    ds2 = xr.open_dataset(f'data/ERA5_variables/{par_name2}.nc',chunks={'lat': -1, 'lon': -1, 'time': -1}).compute()\n",
    "    print(ds2)  \n",
    "    ds = (ds1[par_name1]**2+ds2[par_name2]**2)**0.5\n",
    "    ds = ds.rename(par_name)\n",
    "    return ds\n",
    "def compute_alpha(dataset, par_name1,par_name2, par_name):\n",
    "    ds = np.log(dataset[par_name2]/dataset[par_name1])/np.log(100/10)\n",
    "    ds = ds.rename(par_name)\n",
    "    return ds\n",
    "def compute_gradient(dataset, par_name1,par_name2, par_name):\n",
    "    ds = dataset[par_name2]-dataset[par_name1]\n",
    "    ds = ds.rename(par_name)\n",
    "    return ds\n",
    "\n",
    "def compute_second_derivative(dataset, par_name1,par_name2,par_name3, par_name):\n",
    "    ds = dataset[par_name3]-2*dataset[par_name2]+dataset[par_name1]\n",
    "    ds = ds.rename(par_name)\n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Previously, the wind speeds u and v are not added in the dataset, rather their magnitudes are present. \n",
    "- Now, in addition to the magnitude, I also added u and v components, just incase if the need to be provided as inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u10\n",
      "v10\n",
      "u100\n",
      "v100\n",
      "u_1000\n",
      "v_1000\n",
      "u_975\n",
      "v_975\n",
      "u_950\n",
      "v_950\n",
      "zust\n",
      "i10fg\n",
      "t2m\n",
      "skt\n",
      "stl1\n",
      "d2m\n",
      "msl\n",
      "blh\n",
      "cbh\n",
      "ishf\n",
      "ie\n",
      "tcc\n",
      "lcc\n",
      "cape\n",
      "cin\n",
      "bld\n",
      "t_1000\n",
      "t_975\n",
      "t_950\n"
     ]
    }
   ],
   "source": [
    "combined_dataset = xr.Dataset()\n",
    "\n",
    "par_names = ['u10','v10','u100','v100','u_1000','v_1000','u_975','v_975','u_950','v_950',\n",
    "             'zust','i10fg',\n",
    "            't2m','skt','stl1','d2m','msl','blh','cbh',\n",
    "            'ishf','ie','tcc','lcc','cape','cin','bld','t_1000','t_975','t_950']\n",
    "\n",
    "for par_name in par_names:\n",
    "    file_path = f'data/ERA5_variables/{par_name}.nc'\n",
    "    ds = xr.open_dataset(file_path,chunks={'lat': -1, 'lon': -1, 'time': -1}).compute()\n",
    "    combined_dataset = xr.merge([combined_dataset, ds])\n",
    "    print(par_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 5MB\n",
      "Dimensions:     (location: 18, valid_time: 52584)\n",
      "Coordinates:\n",
      "  * valid_time  (valid_time) datetime64[ns] 421kB 2018-01-01 ... 2023-12-31T2...\n",
      "    latitude    (location) float64 144B 42.75 42.75 43.75 ... 44.25 40.75 43.25\n",
      "    longitude   (location) float64 144B -73.75 -73.75 -76.0 ... -73.5 -77.5\n",
      "  * location    (location) <U9 648B 'PROF_ALB2' 'PROF_ALBA' ... 'PROF_WEBS'\n",
      "    year        (valid_time) int64 421kB 2018 2018 2018 2018 ... 2023 2023 2023\n",
      "Data variables:\n",
      "    u10         (location, valid_time) float32 4MB 3.169 3.012 ... -2.568 -2.74\n",
      "<xarray.Dataset> Size: 5MB\n",
      "Dimensions:     (location: 18, valid_time: 52584)\n",
      "Coordinates:\n",
      "  * valid_time  (valid_time) datetime64[ns] 421kB 2018-01-01 ... 2023-12-31T2...\n",
      "    latitude    (location) float64 144B 42.75 42.75 43.75 ... 44.25 40.75 43.25\n",
      "    longitude   (location) float64 144B -73.75 -73.75 -76.0 ... -73.5 -77.5\n",
      "  * location    (location) <U9 648B 'PROF_ALB2' 'PROF_ALBA' ... 'PROF_WEBS'\n",
      "    year        (valid_time) int64 421kB 2018 2018 2018 2018 ... 2023 2023 2023\n",
      "Data variables:\n",
      "    v10         (location, valid_time) float32 4MB -2.004 -2.463 ... -0.8131\n",
      "<xarray.Dataset> Size: 5MB\n",
      "Dimensions:     (location: 18, valid_time: 52584)\n",
      "Coordinates:\n",
      "  * valid_time  (valid_time) datetime64[ns] 421kB 2018-01-01 ... 2023-12-31T2...\n",
      "    latitude    (location) float64 144B 42.75 42.75 43.75 ... 44.25 40.75 43.25\n",
      "    longitude   (location) float64 144B -73.75 -73.75 -76.0 ... -73.5 -77.5\n",
      "  * location    (location) <U9 648B 'PROF_ALB2' 'PROF_ALBA' ... 'PROF_WEBS'\n",
      "    year        (valid_time) int64 421kB 2018 2018 2018 2018 ... 2023 2023 2023\n",
      "Data variables:\n",
      "    u100        (location, valid_time) float32 4MB 6.232 5.686 ... -3.181 -3.441\n",
      "<xarray.Dataset> Size: 5MB\n",
      "Dimensions:     (location: 18, valid_time: 52584)\n",
      "Coordinates:\n",
      "  * valid_time  (valid_time) datetime64[ns] 421kB 2018-01-01 ... 2023-12-31T2...\n",
      "    latitude    (location) float64 144B 42.75 42.75 43.75 ... 44.25 40.75 43.25\n",
      "    longitude   (location) float64 144B -73.75 -73.75 -76.0 ... -73.5 -77.5\n",
      "  * location    (location) <U9 648B 'PROF_ALB2' 'PROF_ALBA' ... 'PROF_WEBS'\n",
      "    year        (valid_time) int64 421kB 2018 2018 2018 2018 ... 2023 2023 2023\n",
      "Data variables:\n",
      "    v100        (location, valid_time) float32 4MB -3.956 -4.468 ... -0.8804\n",
      "<xarray.Dataset> Size: 5MB\n",
      "Dimensions:     (location: 18, valid_time: 52584)\n",
      "Coordinates:\n",
      "  * valid_time  (valid_time) datetime64[ns] 421kB 2018-01-01 ... 2023-12-31T2...\n",
      "    latitude    (location) float64 144B 42.75 42.75 43.75 ... 44.25 40.75 43.25\n",
      "    longitude   (location) float64 144B -73.75 -73.75 -76.0 ... -73.5 -77.5\n",
      "  * location    (location) <U9 648B 'PROF_ALB2' 'PROF_ALBA' ... 'PROF_WEBS'\n",
      "    year        (valid_time) int64 421kB 2018 2018 2018 2018 ... 2023 2023 2023\n",
      "Data variables:\n",
      "    u_1000      (location, valid_time) float32 4MB 4.849 4.402 ... -2.552 -2.765\n",
      "<xarray.Dataset> Size: 5MB\n",
      "Dimensions:     (location: 18, valid_time: 52584)\n",
      "Coordinates:\n",
      "  * valid_time  (valid_time) datetime64[ns] 421kB 2018-01-01 ... 2023-12-31T2...\n",
      "    latitude    (location) float64 144B 42.75 42.75 43.75 ... 44.25 40.75 43.25\n",
      "    longitude   (location) float64 144B -73.75 -73.75 -76.0 ... -73.5 -77.5\n",
      "  * location    (location) <U9 648B 'PROF_ALB2' 'PROF_ALBA' ... 'PROF_WEBS'\n",
      "    year        (valid_time) int64 421kB 2018 2018 2018 2018 ... 2023 2023 2023\n",
      "Data variables:\n",
      "    v_1000      (location, valid_time) float32 4MB -3.063 -3.472 ... -0.587\n",
      "<xarray.Dataset> Size: 5MB\n",
      "Dimensions:     (location: 18, valid_time: 52584)\n",
      "Coordinates:\n",
      "  * valid_time  (valid_time) datetime64[ns] 421kB 2018-01-01 ... 2023-12-31T2...\n",
      "    latitude    (location) float64 144B 42.75 42.75 43.75 ... 44.25 40.75 43.25\n",
      "    longitude   (location) float64 144B -73.75 -73.75 -76.0 ... -73.5 -77.5\n",
      "  * location    (location) <U9 648B 'PROF_ALB2' 'PROF_ALBA' ... 'PROF_WEBS'\n",
      "    year        (valid_time) int64 421kB 2018 2018 2018 2018 ... 2023 2023 2023\n",
      "Data variables:\n",
      "    u_975       (location, valid_time) float32 4MB 9.522 8.766 ... -3.325 -3.783\n",
      "<xarray.Dataset> Size: 5MB\n",
      "Dimensions:     (location: 18, valid_time: 52584)\n",
      "Coordinates:\n",
      "  * valid_time  (valid_time) datetime64[ns] 421kB 2018-01-01 ... 2023-12-31T2...\n",
      "    latitude    (location) float64 144B 42.75 42.75 43.75 ... 44.25 40.75 43.25\n",
      "    longitude   (location) float64 144B -73.75 -73.75 -76.0 ... -73.5 -77.5\n",
      "  * location    (location) <U9 648B 'PROF_ALB2' 'PROF_ALBA' ... 'PROF_WEBS'\n",
      "    year        (valid_time) int64 421kB 2018 2018 2018 2018 ... 2023 2023 2023\n",
      "Data variables:\n",
      "    v_975       (location, valid_time) float32 4MB -6.266 -6.994 ... -0.6732\n",
      "<xarray.Dataset> Size: 5MB\n",
      "Dimensions:     (location: 18, valid_time: 52584)\n",
      "Coordinates:\n",
      "  * valid_time  (valid_time) datetime64[ns] 421kB 2018-01-01 ... 2023-12-31T2...\n",
      "    latitude    (location) float64 144B 42.75 42.75 43.75 ... 44.25 40.75 43.25\n",
      "    longitude   (location) float64 144B -73.75 -73.75 -76.0 ... -73.5 -77.5\n",
      "  * location    (location) <U9 648B 'PROF_ALB2' 'PROF_ALBA' ... 'PROF_WEBS'\n",
      "    year        (valid_time) int64 421kB 2018 2018 2018 2018 ... 2023 2023 2023\n",
      "Data variables:\n",
      "    u_950       (location, valid_time) float32 4MB 12.16 11.56 ... -3.293 -3.649\n",
      "<xarray.Dataset> Size: 5MB\n",
      "Dimensions:     (location: 18, valid_time: 52584)\n",
      "Coordinates:\n",
      "  * valid_time  (valid_time) datetime64[ns] 421kB 2018-01-01 ... 2023-12-31T2...\n",
      "    latitude    (location) float64 144B 42.75 42.75 43.75 ... 44.25 40.75 43.25\n",
      "    longitude   (location) float64 144B -73.75 -73.75 -76.0 ... -73.5 -77.5\n",
      "  * location    (location) <U9 648B 'PROF_ALB2' 'PROF_ALBA' ... 'PROF_WEBS'\n",
      "    year        (valid_time) int64 421kB 2018 2018 2018 2018 ... 2023 2023 2023\n",
      "Data variables:\n",
      "    v_950       (location, valid_time) float32 4MB -8.584 -9.653 ... 0.1969\n"
     ]
    }
   ],
   "source": [
    "# === derived parameters === #\n",
    "\n",
    "# --- 10m wind ---#\n",
    "ds = compute_wind_speed('u10','v10', '10ws')\n",
    "combined_dataset = xr.merge([combined_dataset, ds])\n",
    "\n",
    "# --- 100m wind ---#\n",
    "ds = compute_wind_speed('u100','v100', '100ws')\n",
    "combined_dataset = xr.merge([combined_dataset, ds])\n",
    "\n",
    "# --- 1000 wind ---#\n",
    "ds = compute_wind_speed('u_1000','v_1000', '1000ws')\n",
    "combined_dataset = xr.merge([combined_dataset, ds])\n",
    "\n",
    "# --- 975 wind ---#\n",
    "ds = compute_wind_speed('u_975','v_975', '975ws')\n",
    "combined_dataset = xr.merge([combined_dataset, ds])\n",
    "\n",
    "# --- 950 wind ---#\n",
    "ds = compute_wind_speed('u_950','v_950', '950ws')\n",
    "combined_dataset = xr.merge([combined_dataset, ds])\n",
    "\n",
    "# --- 100 alpha ---#\n",
    "ds = compute_alpha(combined_dataset,'10ws','100ws','100alpha')\n",
    "combined_dataset = xr.merge([combined_dataset, ds])\n",
    "\n",
    "# --- 1000 wind gradient ---#\n",
    "ds = compute_gradient(combined_dataset,'1000ws','100ws','1000wsgrad')\n",
    "combined_dataset = xr.merge([combined_dataset, ds])\n",
    "\n",
    "# --- 975 wind gradient ---#\n",
    "ds = compute_gradient(combined_dataset,'100ws','975ws','975wsgrad')\n",
    "combined_dataset = xr.merge([combined_dataset, ds])\n",
    "\n",
    "# --- 950 wind gradient ---#\n",
    "ds = compute_gradient(combined_dataset,'975ws','950ws','950wsgrad')\n",
    "combined_dataset = xr.merge([combined_dataset, ds]) \n",
    "\n",
    "# --- 1000 to 950 wind gradient ---#\n",
    "ds = compute_gradient(combined_dataset,'1000ws','950ws','1000to950wsgrad')\n",
    "combined_dataset = xr.merge([combined_dataset, ds])\n",
    "\n",
    "# --- 1000 to 950 wind second derivative ---#\n",
    "ds = compute_second_derivative(combined_dataset,'1000ws','975ws','950ws','1000to950wssecondgrad')\n",
    "combined_dataset = xr.merge([combined_dataset, ds]) \n",
    "\n",
    "# --- skin temperature gradient ---#\n",
    "ds = compute_gradient(combined_dataset,'stl1','skt','sktempgrad')\n",
    "combined_dataset = xr.merge([combined_dataset, ds]) \n",
    "\n",
    "# --- 2m temperature gradient ---#\n",
    "ds = compute_gradient(combined_dataset,'skt','t2m','2mtempgrad')\n",
    "combined_dataset = xr.merge([combined_dataset, ds]) \n",
    "\n",
    "# --- Temperature dewpoint spread ---#\n",
    "ds = compute_gradient(combined_dataset,'d2m','t2m','dewtempsprd')\n",
    "combined_dataset = xr.merge([combined_dataset, ds]) \n",
    "\n",
    "# --- 1000 temperature gradient ---#\n",
    "ds = compute_gradient(combined_dataset,'t2m','t_1000','1000tempgrad')\n",
    "combined_dataset = xr.merge([combined_dataset, ds])\n",
    "\n",
    "# --- 975 temperature gradient ---#\n",
    "ds = compute_gradient(combined_dataset,'t_1000','t_975','975tempgrad')\n",
    "combined_dataset = xr.merge([combined_dataset, ds]) \n",
    "\n",
    "# --- 950 temperature gradient ---#\n",
    "ds = compute_gradient(combined_dataset,'t_975','t_950','950tempgrad')\n",
    "combined_dataset = xr.merge([combined_dataset, ds]) \n",
    "\n",
    "# --- 1000 to 950 temperature gradient ---#\n",
    "ds = compute_gradient(combined_dataset,'t_1000','t_950','1000to950tempgrad')\n",
    "combined_dataset = xr.merge([combined_dataset, ds])\n",
    "\n",
    "# --- 1000 to 950 temperature second derivative ---#\n",
    "ds = compute_second_derivative(combined_dataset,'t_1000','t_975','t_950','1000to950tempsecondgrad')\n",
    "combined_dataset = xr.merge([combined_dataset, ds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === save file ===#\n",
    "file_path = 'data/ERA5.nc'\n",
    "if os.path.exists(file_path):\n",
    "    os.remove(file_path)\n",
    "combined_dataset.to_netcdf(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ERA5 = xr.open_dataset('data/ERA5.nc')\n",
    "combined_dataset = ERA5\n",
    "HR =  pd.to_datetime(ERA5.valid_time).hour\n",
    "# --- sin converted hour ---#\n",
    "ds = xr.DataArray(np.sin(2 * np.pi / 24 * HR), coords=[ERA5.valid_time], dims=['valid_time'], name='sinHR')\n",
    "combined_dataset = xr.merge([combined_dataset, ds])\n",
    "\n",
    "# --- cosine converted hour ---#\n",
    "ds = xr.DataArray(np.cos(2 * np.pi / 24 * HR), coords=[ERA5.valid_time], dims=['valid_time'], name='cosHR')\n",
    "combined_dataset = xr.merge([combined_dataset, ds])\n",
    "\n",
    "JDAY  = pd.to_datetime(ERA5.valid_time).dayofyear\n",
    "# --- sin converted day ---#\n",
    "ds = xr.DataArray(np.sin(2 * np.pi / 366 * JDAY), coords=[ERA5.valid_time], dims=['valid_time'], name='sinJDAY')\n",
    "combined_dataset = xr.merge([combined_dataset, ds])\n",
    "\n",
    "# --- cosine converted day ---#\n",
    "ds = xr.DataArray(np.cos(2 * np.pi / 366 * JDAY), coords=[ERA5.valid_time], dims=['valid_time'], name='cosJDAY')\n",
    "combined_dataset = xr.merge([combined_dataset, ds])\n",
    "\n",
    "# === save file ===#\n",
    "file_path = f'data/ERA5.nc'\n",
    "if os.path.exists(file_path):\n",
    "    os.remove(file_path)\n",
    "combined_dataset.to_netcdf(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding central moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u10\n",
      "v10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harish/miniconda3/envs/TabNet_env/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1879: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harish/miniconda3/envs/TabNet_env/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1879: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v100\n",
      "u_1000\n",
      "v_1000\n",
      "u_975\n",
      "v_975\n",
      "u_950\n",
      "v_950\n"
     ]
    }
   ],
   "source": [
    "ERA5 = xr.open_dataset('data/ERA5.nc')\n",
    "combined_dataset = ERA5\n",
    "\n",
    "#combined_dataset = xr.open_dataset('../data/ERA5.nc')\n",
    "par_names = ['u10', 'v10', 'u100', 'v100','u_1000','v_1000','u_975','v_975','u_950','v_950']\n",
    "\n",
    "for par in par_names:\n",
    "    y = combined_dataset[par]\n",
    "    rolling = y.rolling(valid_time=12,center=False)\n",
    "    y_mean = rolling.mean()\n",
    "    y_std = rolling.std()\n",
    "    y_skew = ((rolling.construct('window_dim') - rolling.reduce(np.mean))**3).mean('window_dim')\n",
    "    y_kurt = ((rolling.construct('window_dim') - rolling.reduce(np.mean))**4).mean('window_dim')\n",
    "\n",
    "    combined_dataset[f'{par}_mean'] = y_mean\n",
    "    combined_dataset[f'{par}_std'] = y_std\n",
    "    combined_dataset[f'{par}_skew'] = y_skew\n",
    "    combined_dataset[f'{par}_kurt'] = y_kurt\n",
    "    print(par)\n",
    "\n",
    "# === save file ===#\n",
    "file_path = f'data/ERA5.nc'\n",
    "if os.path.exists(file_path):\n",
    "    os.remove(file_path)\n",
    "combined_dataset.to_netcdf(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13392\n",
      "u10 0\n",
      "v10 0\n",
      "u100 13392\n",
      "v100 13392\n",
      "u_1000 0\n",
      "v_1000 0\n",
      "u_975 0\n",
      "v_975 0\n",
      "u_950 0\n",
      "v_950 0\n",
      "zust 0\n",
      "i10fg 0\n",
      "t2m 0\n",
      "skt 0\n",
      "stl1 0\n",
      "d2m 0\n",
      "msl 0\n",
      "blh 0\n",
      "cbh 181377\n",
      "ishf 0\n",
      "ie 0\n",
      "tcc 0\n",
      "lcc 0\n",
      "cape 0\n",
      "cin 834406\n",
      "bld 0\n",
      "t_1000 0\n",
      "t_975 0\n",
      "t_950 0\n",
      "10ws 0\n",
      "100ws 13392\n",
      "1000ws 0\n",
      "975ws 0\n",
      "950ws 0\n",
      "100alpha 13392\n",
      "1000wsgrad 13392\n",
      "975wsgrad 13392\n",
      "950wsgrad 0\n",
      "1000to950wsgrad 0\n",
      "1000to950wssecondgrad 0\n",
      "sktempgrad 0\n",
      "2mtempgrad 0\n",
      "dewtempsprd 0\n",
      "1000tempgrad 0\n",
      "975tempgrad 0\n",
      "950tempgrad 0\n",
      "1000to950tempgrad 0\n",
      "1000to950tempsecondgrad 0\n",
      "sinHR 0\n",
      "cosHR 0\n",
      "sinJDAY 0\n",
      "cosJDAY 0\n",
      "u10_mean 198\n",
      "u10_std 198\n",
      "u10_skew 198\n",
      "u10_kurt 198\n",
      "v10_mean 198\n",
      "v10_std 198\n",
      "v10_skew 198\n",
      "v10_kurt 198\n",
      "u100_mean 13788\n",
      "u100_std 13788\n",
      "u100_skew 13788\n",
      "u100_kurt 13788\n",
      "v100_mean 13788\n",
      "v100_std 13788\n",
      "v100_skew 13788\n",
      "v100_kurt 13788\n",
      "u_1000_mean 198\n",
      "u_1000_std 198\n",
      "u_1000_skew 198\n",
      "u_1000_kurt 198\n",
      "v_1000_mean 198\n",
      "v_1000_std 198\n",
      "v_1000_skew 198\n",
      "v_1000_kurt 198\n",
      "u_975_mean 198\n",
      "u_975_std 198\n",
      "u_975_skew 198\n",
      "u_975_kurt 198\n",
      "v_975_mean 198\n",
      "v_975_std 198\n",
      "v_975_skew 198\n",
      "v_975_kurt 198\n",
      "u_950_mean 198\n",
      "u_950_std 198\n",
      "u_950_skew 198\n",
      "u_950_kurt 198\n",
      "v_950_mean 198\n",
      "v_950_std 198\n",
      "v_950_skew 198\n",
      "v_950_kurt 198\n"
     ]
    }
   ],
   "source": [
    "print(combined_dataset['100ws'].isnull().sum().values)\n",
    "# loop over all variables\n",
    "for par in combined_dataset.data_vars:\n",
    "    print(par, combined_dataset[par].isnull().sum().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TabNet_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
